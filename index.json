[{"categories":["数据库"],"content":"论文摘要 传统的数据库分成两种不同类型： 偏重事务处理（online transactional processin, OLTP）：此类数据库将不同属性连续存储，也即按行存储。按行存储可以使得插入/更新/删除更快，毕竟一条数据的所有属性是连续存储的。这种存储模型也叫做 N-Ary Storage Model (NSM)。 偏重数据分析（online analytical processing, OLAP）：此类数据库将不同数据的同一属性连续存储，也即列存储。这种存储可以使得查询操作只读关心的数据属性，而不是一整条数据，减少浪费；按列储存可以更好地支持复杂查询。这种存储模型也叫做 Decomposition Storage Model (DSM)。 很多企业架构中，这两种不同类型的任务分别有不同的技术栈不同的团队完成，且 OLAP（很多情况下也叫商业智能，Business Intelligence） 类的任务一般都离线进行；然而随着时间的推移，数据分析的价值越来越小。且技术上面临如下问题： OLAP 和 OLTP 系统间通常会有几分钟甚至几小时的时延，OLAP 数据库和 OLTP 数据库之间的一致性无法保证，很难满足对分析的实时性要求很高的业务场景。 企业需要维护不同的数据库以便支持两类不同的任务，管理和维护成本高。 企业软件开发团队需要为不同的数据库编写查询语句，且有可能需要将不同系统的数据进行聚合，开发成本高。 本篇论文描述了单一数据库如何支持分析(Hybrid transactional/analytical processing, HTAP) 。 ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:1:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"HTAP 数据库列表 为了应对上述挑战，HTAP 数据库即单一数据库同时支持 OLAP/OLTP业务场景应运而生，比如： 腾讯云 TiDB 阿里云 HybridDB for MySQL 百度 BaikalDB 数据库 MemSQL ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:2:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"HTAP 为什么合理？ 数据刚进入数据库的时，可称之为“热数据”；热数据在 OLTP 场景下会被频繁修改。此时数据宜行存储。 随着数据慢慢变久，数据越来越“冷”；这个时候数据不太可能被频繁的修改，对数据的查询和分析越来越多。此时数据宜列存储。 ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:3:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"如何实现 HTAP？ 本篇论文提供了一种统一的架构，同时支持 OLTP/OLAP： 数据不再纯粹的行存储、或者列存储；而是按照块(Tile)连续存储，即若干属性组成一个块。 数据库执行引擎会实时收集执行的指标，这些指标通过聚类算法(K Means) 实时调整那些一个块由那些属性组成。“热数据” 块涵盖其所有属性，随着数据变“冷”，数据块仅涵盖相关性强的属性；即在行存储和列存储是块存储的两种不同的形式，在块存储中，数据随着时间的推移，慢慢由行存储变成列存储。 物理的数据块之上，提供了一次能够逻辑数据块的抽象，其主要的目的在于使得数据库的执行引擎无需关系数据的存储；操作开始执行的时候创建逻辑块，在最终返回结果的时候，将逻辑快转换成物理块，整个执行过程中，执行引擎无需知道块存储的细节。 HTAP 由于要支持 OLAP 场景，因此并发控制要求读不阻塞写，因此选择 MVCC 作为并发控制。 ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:4:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"总结 在大数据推动行业发展的年代，企业往往选择多种数据库产品，分别支持在线交易、报表生成、日志存储、离线分析等，用以驱动业务的高速发展，但这种组合式解决方案，需要精细的控制不同产品间的数据流转和一致性问题，使用难度颇高，每个数据库产品间的数据同步和冗余，也带来了很高的成本开销，进一步限制了企业级应用的发展。HTAP 数据库在高度可扩展的情况下，同时支持 OLTP/OLAP，是解决这些问题的有效手段。 ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:5:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control ","date":"2018-10-20","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/:6:0","tags":["每周一论文","HTAP","OLAP","OLTP"],"title":"每周一论文：Bridging the Archipelago betweenRow-Stores and Column-Stores for Hybrid Workloads","uri":"https://zhewuzhou.github.io/posts/weekly-paper-bridging-the-archipelago-between-row-stores-column-stores-hybrid-workloads/"},{"categories":["数据库"],"content":"摘要 数据库索引是数据库中最重要的组成部分，而索引的数据结构设计对数据库的性能有重要的影响。本文尝试选取几种典型的索引数据结构，总结分析，以窥数据库索引之全貌。 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:1:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"B+Tree B+Tree 是一种树数据结构，是一个n叉排序树，每个节点通常有多个孩子，一棵B+Tree包含根节点、内部节点和叶子节点。根节点可能是一个叶子节点，也可能是一个包含两个或两个以上孩子节点的节点。 B+Tree 几乎是数据库默认的索引实现，其细节如下： 维基百科在 B+ 树中的节点通常被表示为一组有序的元素和子指针。如果此B+树的序数（order）是m ，则除了根之外的每个节点都包含最少$ {\\displaystyle \\lfloor m/2\\rfloor } \\lfloor m/2\\rfloor$ 个元素最多 m-1 个元素，对于任意的节点有最多 m 个子指针。对于所有内部节点，子指针的数目总是比元素的数目多一个。因为所有叶子都在相同的高度上，节点通常不包含确定它们是叶子还是内部节点的方式。 每个内部节点的元素充当分开它的子树的分离值。例如，如果内部节点有三个子节点（或子树）则它必须有两个分离值或元素 a1 和 a2。在最左子树中所有的值都小于等于 a1，在中间子树中所有的值都在 a1 和 a2 之间((a1，a2]），而在最右子树中所有的值都大于 a2。 B+Tree 有如下性质： 查询时间复杂度为 $O(\\log _{m}n)$ 插入时间复杂度 $O(\\log _{m}n)$ 删除时间复杂度 $O(\\log _{m}n)$ 搜索一个范围的键（k 个键）时间复杂度为 ${\\displaystyle O(\\log _{m}n+k)}$ ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:2:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"B+ Tree 的多线程同步 **搜索：**从根节点开始，获取子节点的读闩，然后释放父节点的读闩；重复这个过程，直到找到目标节点位置。 **插入/删除：**从根节点开始，获取子节点的写闩；重复这个过程，直到找到目标节点位置；如果子节点是安全的，插入/删除不会引起树结构的变化即父节点不需要调整，可释放所有祖先写闩；乐观的插入/删除是先走搜索获得目标节点的读闩，如果目标节点并不安全，则回归上述从根节点获得写闩的过程。 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:2:1","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"Skip List（跳表） Skip List是一种随机化的数据结构，基于并联的链表，其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）。基本上，跳跃列表是对有序的链表增加上附加的前进链接，增加是以随机化的方式进行的，所以在列表中的查找可以快速的跳过部分列表(因此得名)。所有操作都以对数随机化的时间进行。Skip List可以很好解决有序链表查找特定值的困难。 一个跳表，应该具有以下特征： 一个跳表应该有几个层（level）组成； 跳表的第一层包含所有的元素； 每一层都是一个有序的链表； 如果元素x出现在第i层，则所有比i小的层都包含x； 第i层的元素通过一个down指针指向下一层拥有相同值的元素； 在每一层中，-1和1两个元素都出现(分别表示INT_MIN和INT_MAX)； Top指针指向最高层的第一个元素。 相对于 B+Tree，Skip List 有如下优势： B+ Tree 的插入删除操作有可能会引起树结构的变化，需要从新平衡；与之相对的，跳表插入要简单的多，更加简单高效。 B+ Tree 的实现诸如保持树平衡非常复杂；与之相对的，跳表并没有非常复杂的逻辑，实现相对更加简单。 取下一个元素可以再常数时间内，相对于 B+ Tree 的对数时间。 因为链表非常简单，可以很容易的修改跳表结构，以更好地支持诸如范围索引之类的操作。 链表结构使得多线程修改可以仅用 CAS 保证原子性，从而避免重量级的同步机制。 链表的持久化更加简单。 跳表看起来非常像树，比如说检索 跳表横向看来是有很多链表组成，然而指针跳转对于 CPU 缓存 来讲非常不友好，可以用纵向数组来实现跳表以增加 CPU 缓存。 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:3:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"Bw-Tree Hekaton 是微软 SQLServer 专门针对 OLTP 应用场景进行优化的数据库引擎，其索引实现基于 Bw-Tree。Bw-Tree 是一种无需使用任何闩同步的 B+Tree，其主要设计思想如下： Mapping Table（映射表） 映射表存储内存页的ID与其对应的物理内存地址，使得线程可以通过访问映射表找到需要方位的内存地址，映射表的更新通过CAS操作。 不直接修改节点，任何的更新操作都会生成新的数据并通过指针指向被更新节点；新生成的数据所导致的元数据的修改，比如修改映射表都通过 CAS 完成。 垃圾回收，Bw-Tree 通过不断新增数据的方式避免直接修改树节点，在树不断更新的过程中，不可避免的会产生很多垃圾，因此 Bw-Tree 实现了基于 Epoch 的垃圾回收机制：当一个线程想保护一个它正在使用但是将会被回收的对象，例如检索的时候，访问了一个内存页，就把当前线程加入 Epoch，当这个线程完成检索页面的操作后，就会退出 Epoch。通常一个线程在一个epoch的时间间隔内完成一次操作，例如检索。在线程成功加入 Epoch 的时候，可能会看到将要被释放的老版本的对象，但不可能看到已经在前一个 Epoch 中释放的对象，因为其在当前 Epoch 中的操作并不依赖上一个 Epoch 中的数据。因此，一旦所有的线程成功加入Epoch 并完成操作然后退出这个Epoch，回收该 Epoch 中的所有对象是安全的。 由于维护了映射表，和新增数据链，因此树结构调整相对复杂，不仅仅要调整树，切要保证树结构和映射表之间的关系。具体操作可参考此篇文章。 尽管实现非常复杂，Bw-Tree 作为无锁的数据库索引树，有如下优势： 无闩: 实现无锁数据结构十分困难，Bw-Tree 在多线程场景下没有引入任何的闩，只使用 CAS 指令保证线程同步，因此多核的扩展性优于普通用闩同步的B+Tree。 CPU 缓存： 由于不直接修改节点而是追加修改补丁，因此 CPU 缓存不会应为更新数据而失效，因此可以显著提高 CPU 缓存命中率。微软论文中的数据表明，90% 的读操作数据来自 CPU L1/L2 缓存。 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:4:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"Adaptive Radix Tree（自适应基数/前缀树，ART） Radix Tree （基数树)是一种常见的前缀树，Linux Kernel 文件系统就用到了该数据结构： []Hyper 数据库]3中实现了 Adaptive Radix Tree （自适应基数/前缀树，ART）作为其索引。基数树的每个节点可以存储任意长度的键切片，比如 Linux Kernel 中的基数树每个节点存储 6位的键切片；然而数据库索引很多场景下会被频繁修改，每个节点固定长度的键切片会造成时间（切片过长）和空间上（切片过短）的浪费，因此，Hyper 实现了自适应的基数树，也就是节点根据长度的不同分成若干种，随着数据的变化而自行调整。 ART 结构： ART 数据节点类型： 其主要特点有： 树的高度仅取决于键长度。 更新和删除不涉及到树结构的调整，不需要平衡操作。 到达叶子节点的路径就是键。 时间复杂度取决于键的长度，而跟数据量无关，如果数据的增加远远超过键长度的增加，那么使用 ART 将会在性能上带来非常大的收益。 讲述ART同步的论文中提供了描述了两种ART的同步机制： 乐观锁： 读不阻塞写 写操作在获得对应的节点闩之后，更新版本信息 读操作在读下一个结点前，检查版本信息是否发生改变 乐观读悲观写 所有的节点都包含一个互斥锁，当某一个读操作获得此互斥锁之后，阻塞其他写操作 读操作不用获取任何的锁或者闩，也不用检查版本信息 写操作保证同一个节点读操作的数据一致性，即写操作使用原子指令进行写入 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:5:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"Masstree 2012年发表的论文 Cache craftiness for fast multicore key-value storage 提出了 Masstree，其特点如下： 可以理解为B+ Tree 和 Radix Tree 的混合体，即将键切分成多个部分，每个部分为一个节点；每个节点内部又是一个 B+ Tree，兼顾空间和性能。 Masstree将变长键划分成多个固长部分，每个固长部分可以通过int类型表示，而不是char类型。由于处理器处理int类型比较操作的速度远远快于char数组的比较，因此Masstree通过int类型的比较进一步加速了查找过程。固定长度可以设置为 CPU 缓存行长度，以增加 CPU 缓存效率。 每个节点是一个 B+ Tree，因此 CPU 在查询的时候可以将节点所代表的B+ Tree 加载到 CPU 缓存中，以增加 CPU 缓存命中率。 其并发控制用到了Read-Copy-Update(RCU)。读不因任何数据更新而阻塞，但更新数据的时候，需要先复制一份副本，在副本上完成修改，再一次性地替换旧数据。因此读不会造成 CPU 缓存无效。 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:6:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"性能对比 上述几种索引数据结构性能对比如下： ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:7:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 ","date":"2018-10-18","objectID":"https://zhewuzhou.github.io/posts/database-indexes/:8:0","tags":["Skiplist","Bw-Tree","Adaptive Radix Tree","Masstree","B+Tree","索引","无锁"],"title":"数据库索引数据结构总结","uri":"https://zhewuzhou.github.io/posts/database-indexes/"},{"categories":["数据库"],"content":"论文概要 多版本并发控制(Multi-Version Concurrency Control，以下简称MVCC) 是当今数据库领域最流行的并发控制实现，MVCC 在最大化并发度的情况下尽可能保证事务的正确性，其好处有： 写不会阻塞读 只读事务无需数据库锁就能支持可重复读 可以很好地支持历史数据查询 MVCC 的关键在于首先假设数据库读写冲突不会很大，其次通过维护同一份数据的多个版本，是的事务之间的冲突尽可能小；当一个事务修改数据的时候，创建一个新的版本，当一个事务读数据的时候，返回最新版本数据；所有对于数据的修改都发生在事务的私有空间内，在提交的时候进行验证。 当今主流的数据库基本都支持MVCC： 本篇论文系统的总结了 MVCC 的技术要点，包括： 并发控制协议 多版本存储 垃圾回收 索引管理 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:1:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"并发控制协议 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:2:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"MVTO 通过预先计算顺序的方式来控制并发；事务的读操作返回最新的没有被写锁锁定数据的版本；事务的写操作过程如下： 当前没有活跃的事务锁定数据 当前事务的事务编号大于最新数据中的读事务的事务编号 如果这上述条件成立，那么创建一个新的数据版本 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:2:1","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"MVOCC 在 MVOCC 中，事务被分成三个阶段，分别是： 读数据阶段，着这个阶段新的版本被创建出来。 验证阶段，在这个阶段一个提交编号被分配给该事务，然后基于这个编号进行验证； 提交阶段，完成提交。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:2:2","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"MV2PL 顾名思义，MV2PL 是传统的两阶段锁在多版本并发控制中的应用；事务读写或者创建数据版本都需要获得对应的锁。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:2:3","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"SSI 可串行化快照隔离(serializable snapshot isolation或SSI)是在快照隔离级别之上，支持串行化。PosgtreSQL 中实现了这种隔离级别，数据库通过维护一个串行的图移除事务并发造成的危险结构。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:2:4","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"多版本存储 数据库通过无锁指针链表维护多个版本，使得事务可以方便的读取特定版本的数据。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:3:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"仅限追加存储(Append-Only) 所有的版本存储在同一个表空间 更新的时候追加在版本链表上追加新节点 链表可以以最旧到最新的方式组织， 链表也可以以最新到最旧的方式组织，表头为最新版本 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:3:1","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"时序存储(Time-Travel Storage) 每次更新的时候将之前的版本放到旧表空间 更新主表空间中的版本 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:3:2","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"仅差异存储(Delta Storage) 每次更新近存储修改的部分，将其加入链表，主表空间存储当前版本 通过旧的修改部分，可以创建旧版本 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:3:3","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"垃圾回收 MVCC 在事务过程中不可避免的会产生很多的旧版本，这些旧版本会在下列情况下被回收 对应的数据上没有活跃的事务 某版本数据的创建事务被终止 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:4:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"数据行级别垃圾回收(Tuple Level) 通过检查数据来判断是否需要回收旧版本，有两种做法： 启动一个后台线程进行数据行级的垃圾回收 当事务操作数据行时，顺便做一些垃圾回收的事情 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:4:1","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"事务级别垃圾回收(Transaction Level) 事务自己追踪旧版本，数据库管理系统不需要通过扫描数据行的方式来判断数据是否需要回收。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:4:2","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"索引管理 数据有多个版本，而索引只有一份，更新和维护多个版本的时候如何同步索引？ ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:5:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"主键(Primary Key) 主键一般指向多版本链表头 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:5:1","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"副索引(Secondary Indexes) 有两种做法，逻辑指针和物理地址；前者通过增加一个中间层的方式实现，缩影指向该中间层，中间层指向数据的物理地址，避免应为多版本的物理地址改变引起的索引树的更新；后者索引直接指向数据物理地址。 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:5:2","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 ","date":"2018-09-29","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/:6:0","tags":["每周一论文","锁","MVCC"],"title":"每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control","uri":"https://zhewuzhou.github.io/posts/weekly-paper-an-empirical-evalution-of-in-memory-mvcc/"},{"categories":["数据库"],"content":"论文概要 B-Tree 及各种变种数据类型作为数据库索引已经有几十年的历史了，虽然此类数据结构功能简单，无非查询、插入和删除节点；然而并发控制却异常复杂，尤其是涉及到数据库事务的情况下。本篇论文系统的总结了基于 B-Tree 的数据库索引的并发控制，提纲挈领。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:1:0","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"问题定义 数据库中的并发问题分为两类： 多线程并发访问内存数据的同步问题。数据库中有很多线程共享数据，比如数据库的锁定表(Locking Table)。此类问题即编程中常见的并发控制问题，通常大家通过锁(Locking)决此类同步问题，但在数据库同样的技术却被命名为闩(Latchs)，以便却别事务并发。 多个事务并发访问数据库内容的同步问题。比如两个事务并发读写问同一个索引节点，又或者两个事务同时读写同一个内存页。一般解决事务并发会用到锁(Locks)。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:1:1","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"闩的实现 一切闩的基础 CAS(Compare and Swap): 即 CPU 原子指令，对于给定的内存地址M，比较其值A和给定值B CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论V值是否等于A值，都将返回V的原值。CAS 有效地说明了：我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可 数据库闩的实现 操作系统提供的互斥锁(Mutex): 其特点是简单易用；加锁或者释放锁操作需要系统调用，因此非常慢，大概需要几十 ns，大概相当于 100个 CPU 指令，50次 CPU L1 缓存访问。 读写锁(Reader and Writer Lock) 可以基于自旋锁实现；通过维护一个读和一个写的原子计数，允许多线程并发读；读写锁的设计需要考虑很多问题，读和写的优先级如何保证？锁的公平性如何保证？ 检查并设置自旋锁(Test-and-Set Spin Lock): Test-and-Set 是 CPU 的原子指令，给制定内存设置给定的值，并返回旧值。Test-and-Set SpinLock 是操作系统常用的锁技术，比较高效，但并不保证公平性。 排号自旋锁(Queue Based Spin Lock) MCS: 基于链表的自旋锁 MCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。笔者使用 Linux 内核开发者 Nick Piggin 的自旋锁压力测试程序对内核现有的排队自旋锁和 MCS Spinlock 进行性能评估，在 16 核 AMD 系统中，MCS Spinlock 的性能大约是排队自旋锁的 8.7 倍 排号自旋锁有以下特点： 释放自旋锁时，锁的拥有者 A 必须十分小心。如果有直接后继 B，即 A 的 mcs_lock_node 结构的 next 域不为 NULL，那么只须将 B 的 waiting 域置为 0 即可。 如果 A 此时没有直接后继，那么说明 A “可能”是最后一个申请者（因为判断是否有直接后继和是否是最后一个申请者的这两个子操作无法原子完成，因此有可能在操作中间来了新的申请者），这可以通过使用原子比较-交换操作来完成，该操作原子地判断 mcs_lock 是否指向 A 的 mcs_lock_node 结构，如果指向的话表明 A 是最后一个申请者，则将mcs_lock 置为 NULL；否则不改变 mcs_lock 的值。无论哪种情况，原子比较-交换操作都返回 mcs_lock 的原值。 如果A 不是最后一个申请者，说明中途来了新的申请者 B，那么 A必须一直等待 B 将链表构建完整，即 A 的 mcs_lock_node 结构的 next 域不再为 NULL。最后 A 通过 next 域将 B 的 waiting 域置为 0。 无论数据库的读写，都可能需要遍历索引数；其操作过程中闩的使用如下： 搜索：从根节点开始，获取子节点的读闩，然后释放父节点的读闩；重复这个过程，直到找到目标节点位置。 插入/删除：从根节点开始，获取子节点的写闩；重复这个过程，直到找到目标节点位置；如果子节点是安全的，插入/删除不会引起树结构的变化即父节点不需要调整，可释放所有祖先写闩；乐观的插入/删除是先走搜索获得目标节点的读闩，如果目标节点并不安全，则回归上述从根节点获得写闩的过程。 虽然闩能够保证多线程修改临界内存的操作线程安全，但由于释放闩是在索引节点级别，而不是事务级别，因此仅仅用闩，还是可能导致幻读的问题。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:1:2","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"锁的实现 不同于闩，锁是用来保证和解决数据库事务之间的并发问题，而不是数据库内存临界关键数据结构的并发问题；因此闩和锁的主要实现区别有： 一旦某个事务获取了锁，则锁在该事务的整个生命周期发挥作用。因此事务级别的并发问题如幻读可以使用锁来解决。数据库的隔离等级也通过锁完成。 仅就数据库索引而言，事务从索引树叶子节点获得锁。 锁不跟索引树存放在一起，而是存放在锁表中；因为锁表也属于多线程共享资源，因此事务访问锁表需要用到闩。 即便使用最慢的操作系统互斥锁，闩的获取和释放可以再100个 CPU 指令以内完成；而数据库锁的获取和释放往往在1000个 CPU 指令以上。 当然锁仅仅是事务并发同步的一种方式，数据库也往往通过诸如 MVCC 等技术实现事务之间的同步，尽量避免用锁（访问锁表）。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:2:0","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"锁类型 键值锁(Key Value Locking)：顾名思义，这种锁的作用范围限于一个索引节点。 间隙锁(Gap Locking)：Gap就是索引树叶子节点中插入新记录的间隙。相应的间隙锁就是加在间隙上的锁。一般情况下，事务一般首先获取键值锁，然后获取键值锁相邻的间隙锁。索引树插入新值得情况下，需要获取间隙锁。 键范围锁(Key Range Locking)：事务锁定一个范围内的键，一般情况下，事务一般首先获取键值锁，并且获取键值锁相邻的间隙锁，因此范围键锁可以考虑为一个键值锁加一个间隙锁。 层级锁(Hierarchical Locking)：相对于前面的三中锁，这种锁的实现相对复杂；这种锁允许数据库在较大索引范围内锁定索引表，然后在此大范围锁中定义其他粒度较小的锁，如上述的三种锁。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:2:1","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"数据库无锁实现的含义 通常情况下，数据库无锁实现是下面两种情况之一： 事务在进行过程中不获取锁，但通过闩来保证写入线程安全。比如 MVCC。 数据库通过原子指令完成更新写入，即不需要闩来保障线程安全，但事务在提交的时候需要通过锁来进行事务验证。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:3:0","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"实际案列 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:4:0","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"MySQL 中的锁 MySQL 的 InnoDB 引擎支持行锁和表锁，其中行锁相对于表锁粒度小而并发性好，其行锁包括： 键值锁(Key Value Locking) 间隙锁(Gap Locking) 键范围锁(MySQL 中也叫做 Next Key Locking) ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:4:1","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"PostgreSQL 中的锁 默认情况下： PostgreSQL利用多版本并发控制(MVCC)来维护数据的一致性。这就意味着当检索数据时，每个事务看到的都只是一小段时间之前的数据快照(一个数据库版本)，而不是数据的当前状态。这样，如果对每个数据库会话进行事务隔离，就可以避免一个事务看到其它并发事务的更新而导致不一致的数据。MVCC通过避开传统数据库系统锁定的方法，最大限度地减少锁竞争以允许合理的多用户环境中的性能。 PostgreSQL 也支持显示的行级锁 FOR UPDATE：令那些被SELECT检索出来的行被锁住，就像在更新一样。这样就避免它们在当前事务结束前被其它事务修改或者删除；也就是说， 其它企图UPDATE, DELETE, SELECT FOR UPDATE, SELECT FOR NO KEY UPDATE,SELECT FOR SHARE 或 SELECT FOR KEY SHARE 这些行的事务将被阻塞，直到当前事务结束。同样， 如果一个来自其它事务的UPDATE,DELETE,SELECT FOR UPDATE已经锁住了某个或某些选定的行，SELECT FOR UPDATE将等到那些事务结束，并且将随后锁住并返回更新的行(或者不返回行，如果行已经被删除)。但是，在REPEATABLE READ或SERIALIZABLE事务内部，如果在事务开始时要被锁定的行已经改变了，那么将抛出一个错误。 FOR NO KEY UPDATE：的行为类似于FOR UPDATE，只是获得的锁比较弱：该锁不阻塞尝试在相同的行上获得锁的SELECT FOR KEY SHARE命令。该锁模式也可以通过任何不争取FOR UPDATE锁的UPDATE获得。 FOR SHARE：的行为类似于FOR NO KEY UPDATE，只是它在每个检索出来的行上获得一个共享锁，而不是一个排它锁。一个共享锁阻塞其它事务在这些行上执行UPDATE,DELETE,SELECT FOR UPDATE或SELECT FOR NO KEY UPDATE，却不阻止他们执行SELECT FOR SHARE或SELECT FOR KEY SHARE。 FOR KEY SHARE：的行为类似于FOR SHARE，只是获得的锁比较弱： 阻塞SELECT FOR UPDATE但不阻塞SELECT FOR NO KEY UPDATE。一个共享锁阻塞其他事务执行DELETE或任意改变键值的UPDATE， 但是不阻塞其他UPDATE，也不阻止SELECT FOR NO KEY UPDATE, SELECT FOR SHARE 或SELECT FOR KEY SHARE。 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:4:2","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 ","date":"2018-09-25","objectID":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/:5:0","tags":["每周一论文","事务","并发","锁","闩","MySQL","PostgreSQL"],"title":"每周一论文：A Survey of B-Tree Locking Techniques","uri":"https://zhewuzhou.github.io/posts/weekly-paper-a-survey-of-b-tree-locking-techniques/"},{"categories":["数据库"],"content":"数据库性能之翼：SQL 语句运行时编译 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:0:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"摘要 现代服务器的一大特点是内存越来越大，对于运行在这些服务器上的数据库，性能的瓶颈是 CPU 而非内存；然而传统 SQL 执行模型即“火山模型” 诞生于内存是瓶颈的年代，其以行为单位的迭代执行过程虽然灵活，但对 CPU 非常不友好。 在这个大背景下，SQL 语句运行时编译技术应运而生，为传统的关系型数据库的 SQL 执行性能插上翅膀。 一些 SQL 编译的实现如下： Apache Spark Tungsten 引擎运行时将 SQL 语句的 Where 部分转换成抽象语法树，然后再讲抽象语法树运行时编译成 Java 字节码。 Oracle 数据库将 SQL 语句运行时转换为 C\\C++ 代码，然后将其编译为机器码。 Postgres 11 中提供了基于 LLVM 的即时编译(JIT) 的 SQL 语句执行引擎。有实验证明 Postgres 上 SQL 语句编译技术能够将 Postgres 的事务处理能力提升20%之500%。 随着 CPU 和多核瓶颈日益凸显，SQL 语句编译技术会成为重要的数据库性能提升技术。希望读者通过本篇博客能够了对 SQL 编译技术有个大概的认识。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:1:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"为什么要进行 SQL 编译 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:2:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"通用（抽象） vs 定向优化 SQL 是一个非常优秀的抽象模型；对于使用者来讲，SQL 简单易用，不用关心 SQL 背后的诸如存储、同步及先写日志等细节；从而使得： SQL 可以运行在任何一台计算机上 开发人员不需要关心 SQL 语句的执行过程，通过陈述的方式描述业务逻辑 另外一方面，现代的计算机硬件在不断进步，SQL 语句运行速度的关键是针对这些硬件进行定向优化。 SQL 运行时编译正好可以弥补通用抽象和定向优化之间的性能差距。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:2:1","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"火山模型 火山模型是数据库成熟的 SQL 语句解释执行方案，该模型是一个数据库执行器实现中非常流行的“设计模式”。该设计模式将关系型代数中的每一种操作抽象成一个 Operator，整个 SQL 语句在这种情况下形成一个 Operator 树；通过自顶向下的调用 next 接口，火山模型能够以数据库行为单位处理数据。 火山模型有如下特点： 首先该模型以数据行为单位处理数据，每一行数据的处理，都会调用 next 接口多次；当 SQL 语句涉及的数据行数特别多的情况下，next 的调用次数会相当大。 next 接口的调用，是通过虚函数机制；相比于直接调用函数，虚函数机制需要的 CPU 指令更多，因此也更加昂贵。 以行为单位的数据处理，会导致 CPU 缓存使用效率低下和一些不必要的复杂性；首先数据库必须记住处理到哪一行，以便处理跳到下一行；其次处理完一行后需要将下一行加载到 CPU 缓存中，而实际上 CPU 缓存所能存储的数据行数远不止一行。 火山模型最大的好处是工程上非常干净，每个Operator有良好的抽象，只需要关心自己负责的逻辑就可以，比如Filter只需要关心如何根据谓词过滤数据，Aggregates只需要关心如何聚合数据。 一言以蔽之，火山模型首先会导致更多的 CPU 指令，更为严重的是会导致 CPU 缓存效率低下，严重影响数据库的性能；而 SQL 语句编译技术就是针对这些问题进行优化。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:2:2","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"SQL 编译技术细节 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:3:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"减少不必要的指令 从根本上讲，提高数据库性能的方法是减少 CPU 指令数量；有实验之处数据库处理事务过程中，正真有用的指令，即用于事务逻辑的指令不到5% SQL 语句编译成机器码的过程，就是通过优化有效的降低 CPU 指令数的过程。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:4:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"增加 CPU 缓存效率 火山模型以 Operator 为中心进行事务处理，其弊端非常明显；SQL 编译技术为了最大可能的将数据保留在 CPU 寄存器中，采取如下措施： 以数据为中心，同事处理多行数据，而不是一行；自底向上，而不是自顶向下。 SQL 通过 LLVM 编译成机器码，编译优化使得数据能够尽可能久的停留在CPU寄存器中。实际上编译成机器码使得 SQL 语句能够得到硬件和编译器优化技术进步带来的替身，这是火山模型无法匹敌的。 同一批数据尽可能久的停留在 CPU 寄存器中，即数据不变而 Operator 流转，相比于火山模型，这种方式更像是数据不断地被 Push 给 Operator，而不是 Operator Pull 数据。 这种以多行数据为单位，基于 Push 的技术应用于数据库 SQL 执行引擎，可带来5倍的性能提升。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:5:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"代码生成 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:6:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"代码到代码 这种方式基本上是将 SQL 语句转换成 C\\C++ 代码，有如下特点： 对于给定的 SQL 语句，通过模板将其替换为同等逻辑的 C\\C++ 代码，然后编译成机器码 一般情况下会另起一个进程或者线程，运行诸如 gcc 等成熟的编译器，对生成的 C\\C++ 代码进行一步编译 编译好的代码通过运行时链接，可调用数据库其他方法 这种方式能够带来 SQL 语句执行效率的提升，然而如果 SQL 语句过大，可能导致编译时间长，总体时间反而不如解释执行的情况。 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:6:1","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"JIT 这种方式并非将 SQL 语句直接编译成机器码，而是首先将其编译成中间代码，比如 LLVM IR，有如下特点： 由于 JIT 的方式使得数据库编译器拥有 SQL 运行时的数据，通过数据生存周期分析等技术优化，有针对性的进行优化和编译，让数据能够尽可能久的停留在 CPU 缓存中；上述 Push 数据的 SQL 执行引擎成基于 JIT 实现。 SQL 语句编译并非没有代价，实际上编译时间和 SQL 语句的复杂程度是线性关系；由于编译器拥有运行时数据，且数据库引擎以一组数据单位，因此编译器可以实时评估收益，在执行下一组数据的时候在如下方式间灵活无缝的切换： 简单 SQL 语句解释执行 中等规模的SQL 语句不经优化编译成机器码执行 复杂的的 SQL 语句深度优化编译成机器码执行 简单的算法如下 //Dispatch dispatch(handleB, state): nextMorsel = grabMorsel() if (handleB.isCompiled()): handleB.fn(state, nextMorsel) else: VM.execute(handleB.byteCode, state, nextMorsel) choice = choice = extrapolatePipelineDurations(...) if (choice != DoNothing): unAsync(λ -\u003e handleB.fn = handleB.compile(choice)) //Evaluate // f: worker function // n: remaining tuples // w: active worker threads extrapolatePipelineDurations(f, n, w): r0 = avg(rateinthreadRates) r1 = r0*speedup1(f); c1 = ctime1(f) r2 = r0*speedup2(f); c2 = ctime2(f) t0 = n / r0 / w t1 = c1 + max(n - (w-1)*r0*c1, 0) / r1 / w t2 = c2 + max(n - (w-1)*r0*c2, 0) / r2 / w switchmin(t0, t1, t2): case t0: return DoNothing case t1: return Unoptimized case t2: return Optimized ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:6:2","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 ","date":"2018-09-13","objectID":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/:7:0","tags":["关系型数据库","SQL","SQL语句编译","高性能","JIT"],"title":"数据库性能之翼：SQL 语句运行时编译","uri":"https://zhewuzhou.github.io/posts/sql_compilation_technology_for_performance/"},{"categories":["Framework"],"content":"摘要 最近写代码，遇到一个 奇怪的Spring AOP 有关的问题；本文从这个问题出发，通过问问题的方式揭示这个问题背后深层原因。 ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:1:0","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"AOP 问题代码清单 AOP Aspect: HttpHeaderValidator.java @Aspect public class HttpHeaderValidator { @Before public void isUserInfoExist(){ ... } } AOP Joint Point: Logger.java @Aspect public class Logger { public void logTransactionA(){ String user = this.getUserFromHeader(); ... } public void logTransactionB(){ String user = this.getUserFromHeader(); ... } @UserValidator public String getUserFromHeader(){ ... } } 代码的逻辑是，通过 UserValidator 将检查 Http Header 用户信息的切片逻辑插入到方法 getUserFromHeader() 之前；由于 Logger 类多处写日志的方法都会调用 getUserFromHeader() 因此，也就等价于多处写日志的时候都会进行 Header 的检查，避免了在每一个写日志的方法上加上 annotation. 然而执行代码却发现切片逻辑根本没有被执行；如果换种写法，把 UserValidator 加到每一个写日志的方法上，切片逻辑被调用了；这是为什么呢？ ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:2:0","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"表面原因 Spring AOP 文档中有如下描述： Okay, so what is to be done about this? The best approach (the term best is used loosely here) is to refactor your code such that the self-invocation does not happen. For sure, this does entail some work on your part, but it is the best, least-invasive approach. The next approach is absolutely horrendous, and I am almost reticent to point it out precisely because it is so horrendous. 上述代码切面逻辑之所以没有被调用，原因在于方法 getUserFromHeader 的调用发生在类 Logger 内部 (self-invocation) , 因此上述代码是不工作的，Spring官方文档 还给出了一段解释： The key thing to understand here is that the client code inside the main(..) of the Main class has a reference to the proxy. This means that method calls on that object reference will be calls on the proxy, and as such the proxy will be able to delegate to all of the interceptors (advice) that are relevant to that particular method call. However, once the call has finally reached the target object, the SimplePojo reference in this case, any method calls that it may make on itself, such as this.bar() or this.foo(), are going to be invoked against the this reference, and not the proxy. This has important implications. It means that self-invocation is not going to result in the advice associated with a method invocation getting a chance to execute. 按照这个解释，在 logTransactionA() 方法被调用的时候，其内部调用 getUserFromHeader() 指向的是 this 也就是 Logger 类对象，而不是调用前插入切片逻辑的的代理方法。 只要注意写 AOP 代码的时候不要出现内部调用代理方法，似乎这个问题就得到了解决。然而更多的问题浮现出来： 为什么内部调用会导致 Spring AOP 失效? 为什么内部调用的时候调用指向 this 指针而非 proxy 方法？ ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:3:0","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"进一步思考 内部调用导致 Spring AOP 失效的问题本质实际上是一个设计问题；要弄清楚这个问题，需要在更高的层次上了解更多的细节。 ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:4:0","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"AOP 的几种编织方式 在进一步探索之前有必要了解下 AOP 的几种编织方式；所谓编织即切片逻辑插入切入点的过程；有编译时编织、加载时编织和运行时编织等多种方式，Spring AOP 的编织方式是运行时编织；尽管编译时编织提供更好的灵活性，比如甚至可以将切片逻辑插入到某一具体代码行附近，然而相比于运行时编织其依赖更多。 运行时编织：即运行时基于 Java Dynamic Proxy 特性（基于接口），或者基于 CGLib、ByteBuddy 等（基于实现类），通过子类 (Proxy) 的方式将切片逻辑和切入点函数调用粘连到一起；Spring AOP 实际上是运行时编织，其编织粒度是函数运行级。 ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:4:1","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"新问题 既然 Spring AOP 通过 Proxy 也就是 Subclass 的方式实现，那么其他类调用方法 logTransactionA() 时候实际上通过代理，而代理除了切片逻辑之外，肯定需要调用父类 Logger 的 logTransactionA() 方法，假设其调用方式为 super.logTransactionA()，那么由于多态的存在，最终 代理类中 getUserFromHeader() 应该被调用，也就是即便是内部调用，切片逻辑也应该被调用到；既然 AOP 在内部调用场景下失效，那么代理类在调用父类的方法的时候，必然不是简单的 super.logTransactionA()，那么代理类究竟是如何调用父类的方法的呢？ 这个问题可以再源码中找到答案，首先 Spring AOP 的某人代理创建工厂如下： public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException { if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) { Class\u003c?\u003e targetClass = config.getTargetClass(); if (targetClass == null) { throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); } if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) { return new JdkDynamicAopProxy(config); } return new ObjenesisCglibAopProxy(config); } else { return new JdkDynamicAopProxy(config); } } 基于 CGlib 的 ObjenesisCglibAopProxy 会创建 Proxy 对象，然后通过 CGLib 回调的方式，切片逻辑被插入到切入点。限于篇幅，有关于 CGLib Callback 的细节请参考 CGLib Callback 细节 本文所举的 Spring AOP 场景下，最终回调类 DynamicAdvisedInterceptor 的 intercept 方法会被调用，这个方法如下： public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try { if (this.advised.exposeProxy) { // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool... target = targetSource.getTarget(); Class\u003c?\u003e targetClass = (target != null ? target.getClass() : null); List\u003cObject\u003e chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() \u0026\u0026 Modifier.isPublic(method.getModifiers())) { // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); } else { // We need to create a method invocation... retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); } retVal = processReturnType(proxy, target, method, retVal); return retVal; } finally { if (target != null \u0026\u0026 !targetSource.isStatic()) { targetSource.releaseTarget(target); } if (setProxyContext) { // Restore old proxy. AopContext.setCurrentProxy(oldProxy); } } } 调用 proxy 类同名方法，最终会通过 CGlib 调用到对应的回调类 intercept 方法，在调用此方法的时候具体的父类方法和参数都被具化 (Method 类)；也就是在最后的调用中一定是通过被代理类的实例完成调用，即表面上通过代理继承父类的方式，实际上子类在调用父类方法的时候通过父类的实例调用，因此在本文描述的内部调场景下，切片逻辑没有被调用。 public Object invoke(Object obj, Object[] args) throws Throwable { try { init(); FastClassInfo fci = fastClassInfo; return fci.f1.invoke(fci.i1, obj, args); } catch (InvocationTargetException ex) { throw ex.getTargetException(); } catch (IllegalArgumentException ex) { if (fastClassInfo.i1 \u003c 0) throw new IllegalArgumentException(\"Protected method: \" + sig1); throw ex; } } 上面的源码摘自 ProxyMethod ，父类的方法正是通过这个方法被调用的，这里可以看参数 obj ，这个参数正是父类的实例，而这正是多态没有生效的真正原因。 ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:4:2","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["Framework"],"content":"总结 本文从一个 Spring AOP 失效的场景出发，通过 Spring 官方文档，发现其有讲到本文所描述的内部调用场景下 AOP 会失效，然而并没有给出确切的原因。 如果考虑多态，即便是内部调用，AOP 也不该失效；通过源码和 Spring AOP 的设计思想，内部调用正真的失效原因如下： Spring AOP 不支持编译时编织；而编译时编织提供了最大的灵活性，支持内部调用 AOP 并不是难事。 最终当父类的方法被调用的时候，已经是具体化了 Method 类，因此多态不会生效。 ","date":"2018-09-01","objectID":"https://zhewuzhou.github.io/posts/spring_aop_trap/:5:0","tags":["Spring","AOP"],"title":"Spring AOP：内部调用陷阱","uri":"https://zhewuzhou.github.io/posts/spring_aop_trap/"},{"categories":["JVM"],"content":" 摘要 为什么需要关注垃圾回收器？ 垃圾回收关键 - 标记 根集合 CMS 回收器标记 G1 回收器标记 SATB 算法 C4/Z 回收器标记 结论 引用 摘要 垃圾回收作为 Java 语言的重要特性，把开发人员从繁重的内存管理中解放出来，极大的 提高了生产效率。尽管市面上有形形色色不同的垃圾回收器，Hotspot 自带且成熟的有： Serial GC Parallel GC Parallel Old GC (Parallel Compacting GC) Concurrent Mark \u0026 Sweep GC (or “CMS”) Garbage First (G1) GC(Java 9 默认) Oracle 正在开发或者处于试验阶段的垃圾回收有： ZGC，高吞吐量，低延时的 GC，承诺最大垃圾回收造成的应用暂停时间不大于 10 ms， 无论堆和存活对象大小多少。1 Epsilon GC2 ，测试目的 GC 此外，还有不少非 Oracle 主导的 GC ，比如 Redhat 的 Shenandoah GC3 ，Azul 的 C4 GC 等。 形形色色的垃圾回收器让人眼花缭乱，遑论繁多的配置参数；本文试图通过提供一组通用 的视角，使得开发人员可以透过现象看本质，更好的理解和使用垃圾回收器，本篇文章主 要关注垃圾回收器的标记过程。 为什么需要关注垃圾回收器？ 在回答以上问题之前，有一个根本的问题需要回答，那就是作为一个应用程序开发人员， 为什么需要关注垃圾回收器？ 实际上，尽管垃圾回收器在大多数情况下都是高效的，以至于大多数开发人员根本没有察 觉到它的存在；然而在另外一些场景下： 垃圾回收器并不意味着没有内存泄露。4 垃圾回收器可能导致超过 30s 的应用暂停。5 因此，即使作为应用程序开发人员，了解和学习垃圾回收器也是必要的，至少在遇到上面 两种情况的时候，可以是的开发人员更快的解决问题。 垃圾回收关键 - 标记 程序运行过程中产生的无用对象即已死对象。对于一个程序员来讲，利用经验或者的知识 可以轻易判断一个对象已死；垃圾回收器作为一个程序，并没有可利用的经验或者知识来 做出同样的判断，因之，通过程序判断对象已死的方式如下： 编译时分析 引用计数 可达性分析 本文主要讨论的主题是 JVM 上的垃圾回收，而在 JVM 上目前已知的垃圾回收器都基于可 达性分析；因此本文的所有描述都基于可达性分析算法。 如果一个对象可以通过当前活跃的线程“可达”，那么就判定该对象为存活对象。例如对象 对象的引用直接在活跃线程的栈上面，此种情况可称为直接可达；如果该对象持有其对象 的引用，那么这些其他对象亦可称之为可达。因此，可达性分析的关键就在于找出直接可 达的对象，这些直接可达的对象也被称为“根集合”。 可达性分析的关键在于找出那些可达也即存活的对象，其他的对象就可以视为垃圾进行回 收。那么那些对象可以算作“根集合”？ 根集合 在 ZGC 中跟集合如下： class ZRootsIterator { private: ZOopStorageIterator _vm_weak_handles_iter; ZOopStorageIterator _jni_handles_iter; ZOopStorageIterator _jni_weak_handles_iter; ZOopStorageIterator _string_table_iter; void do_universe(OopClosure* cl); void do_vm_weak_handles(OopClosure* cl); void do_jni_handles(OopClosure* cl); void do_jni_weak_handles(OopClosure* cl); void do_object_synchronizer(OopClosure* cl); void do_management(OopClosure* cl); void do_jvmti_export(OopClosure* cl); void do_jvmti_weak_export(OopClosure* cl); void do_jfr_weak(OopClosure* cl); void do_system_dictionary(OopClosure* cl); void do_class_loader_data_graph(OopClosure* cl); void do_threads(OopClosure* cl); void do_code_cache(OopClosure* cl); void do_string_table(OopClosure* cl); ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_universe\u003e _universe; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_object_synchronizer\u003e _object_synchronizer; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_management\u003e _management; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_jvmti_export\u003e _jvmti_export; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_jvmti_weak_export\u003e _jvmti_weak_export; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_jfr_weak\u003e _jfr_weak; ZSerialOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_system_dictionary\u003e _system_dictionary; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_vm_weak_handles\u003e _vm_weak_handles; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_jni_handles\u003e _jni_handles; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_jni_weak_handles\u003e _jni_weak_handles; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_class_loader_data_graph\u003e _class_loader_data_graph; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_threads\u003e _threads; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_code_cache\u003e _code_cache; ZParallelOopsDo\u003cZRootsIterator, \u0026ZRootsIterator::do_string_table\u003e _string_table; public: ZRootsIterator(); ~ZRootsIterator(); void oops_do(OopClosure* cl, bool visit_jvmti_weak_export = false); }; 尽管源码中用于枚举根集合的类型有超过十种，但大体上，可以归纳为三类： 包含指向堆栈引用的全局变量。 包含指向堆栈引用的寄存器变量。 包含指向堆栈引用的栈内变量。 现在垃圾回收器可以基于以上的根集合来枚举存活对象；为了降低应用程序响应时间，现 代的垃圾回收器基本都是并行增量标记；然而标记过程中仍然会遇到很多挑战： 应用程序线程将一个未标记的对象引用读入 CPU 缓存，然后从内存中删除该对象。 未标记的对象被存储到已经标记的区域。 为了解决类似上述的问题，垃圾回收器的设计者们需要考虑一下问题： Stop The World 是简单粗暴的问题解决办法，可以使得 GC 标记尽可能精准；但这是 以应用程序响应时间为代价的，如何在标记过程中尽量避免 Stop The World? 整个标记过程需要全局扫描和跟踪堆上的对象，时间相对较长，为了使得必要的 Stop The World 尽量短，有必要对标记过程进行切分，使得标记过程分成不同的阶段，如何 划分不同的阶段？ CMS 回收器标记 CMS 算法标记过程一般描述： 初始标记(initial-mark)：从GC Root开始，仅扫描与根节点直接关联的对象并标记， 这个过程需要 Stop The World，但是GC Root数量有限，因此时间较短 并发标记(concurrent-marking)：这个阶段在初始标记的基础上继续向下进行遍历标记。 这个阶段与用户线程并发执行，因此不停顿 重新标记(remark)：重新标记阶段会对堆上的对象进行扫描，以对并发标记阶段遭到破 坏的对象引用关系进行修复，以保证执行清理之前对象引用关系是正确的。这一阶段需 要STW，时间也比较短暂 需要说明的是在 CMS 一个垃圾回收的周期中，在对象或者","date":"2018-08-27","objectID":"https://zhewuzhou.github.io/posts/gc_marking/:0:0","tags":["Java","GC-Marking","Pauseless-GC"],"title":"GC 标记算法：从分阶段标记到无停顿标记","uri":"https://zhewuzhou.github.io/posts/gc_marking/"},{"categories":["JVM"],"content":"SATB 算法 G1 使用的是 SATB 标记算法，主要应用于垃圾收集的并发标记阶段，解决了CMS 垃圾收 集器重新标记阶段长时间 Stop The World 的潜在风险。其算法全称是 Snapshot At The Beginning，由字面理解，是垃圾回收器开始时活着的对象的一个快照。它是通过 “根集合”穷举可达对象得到的，穷举过程中采用了三色标记法： 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 灰：对象被标记了，但是它的field还没有被标记或标记完。 黑：对象被标记了，且它的所有field也被标记完了。 在并发标记的过程中，应用程序可能会修改对象，使得一个白色对象被漏标 应用程序插入了一个从黑色对象到该白色对象的新引用 应用程序删除了所有从灰色对象到该白色对象的直接或者间接引用。 SATB 利用 write barrier 将所有即将被删除的引用关系的旧引用记录下来，最后以这 些旧引用为根 Stop The World 地重新扫描一遍即可避免漏标问题。 因此 G1 Remark阶 段 Stop The World 与 CMS 了的remark有一个本质上的区别，那就是这个暂停只需要扫 描有 write barrier 所追中对象为根的对象， 而 CMS 的 remark 需要重新扫描整个根 集合，因而CMS remark有可能会非常慢。 C4/Z 回收器标记 C4/Z 整个垃圾回收期间都不需要 Stop The World，是无停顿（Pauseless)垃圾回收器， 因此其标记过程也是并行的，因此 C4/Z 无视堆的大小和存活对象的多少，可以提供至多 10ms 的应用程序暂停，实际上这是非常保守的说法。 C4/Z 也是采用了增量的并行标记，跟 G1/CMS 相比，不同点在于： 采用 Checkpoint 的方式，应用程序线程无需停顿，尤其是在初始标记，穷举根集合 的阶段，Checkpoint 是应用程序线程到达一个 Safepoint ，完成少量垃圾回收的工 作，然后继续业务逻辑，而垃圾回收器要等到所有的应用程序经过 Checkpoint 后， 才能开始一个垃圾回收周期；这一点跟 G1/CMS 完全不同，在G1/CMS initial mark 阶段所有的应用程序必须要处于 Safepoint 或者 Saferegion，因此存在所有的应用 程序线程需要等最慢到达 Safepoint 线程的情况。 在标记过程中，新对象分配在新的内存页上，新的内存页在标记过程中被忽略。 CMS/G1 使用 write barrier 由垃圾回收器线程完成追踪对象的变化，而 C4/Z 则使 用 read barrier 且由应用程序完成增量标记的任务；这种应用程序通过硬件中断自 行修复标记的过程也被成为 “Self healing”。7 通过这些不同的技术，C4/Z 在整个标记过程中都不需要 Stop The World。 结论 随着硬件的不断提升和用户体验要求不断被拔高，人们对应用程序的响应时间要求越来越 苛刻。在这个大背景下，垃圾回收器的标记技术也不短的在改变。 本文通过分析 CMS/G1/Z/C4 垃圾回收器的标记过程，揭示出 Java 垃圾回收器的一大技 术趋势，即在大内存堆的前提下尽 GC 可能的降低对应用程序的影响；从 CMS 的分阶段 增量标记，到 G1 通过 SATB 算法改正 remark 阶段的 Stop The World 的影响，再到 Z/C4甚至在标记阶段无需 Stop The World，莫不如此。 引用 1. https://wiki.openjdk.java.net/display/zgc/Main 2. https://wiki.openjdk.java.net/display/shenandoah/Main 3. http://openjdk.java.net/jeps/318 4. https://medium.com/@plumbr/memory-leaks-fallacies-and-misconce-8c79594a3986 5. https://medium.com/ai-build-techblog/jvm-garbage-collector-murder-mystery-1b6a4aec5117 6. http://www.cs.ucsb.edu/~ckrintz/racelab/gc/papers/ossia-concurrent.pdf 7. https://www.usenix.net/events/vee05/full_papers/p46-click.pdf ","date":"2018-08-27","objectID":"https://zhewuzhou.github.io/posts/gc_marking/:1:0","tags":["Java","GC-Marking","Pauseless-GC"],"title":"GC 标记算法：从分阶段标记到无停顿标记","uri":"https://zhewuzhou.github.io/posts/gc_marking/"},{"categories":["数据库"],"content":"目录 摘要 SQL 的现在 Not Only SQL 要水平扩展，也要 SQL 总结 引用 摘要 毫不夸张的说，关系数据库是企业软件系统的核心，企业形形色色信息行为的背后，都有 关系数据库的支撑。 SQL 作为关系型数据库最重要的功能之一，有着悠久的历史。 随着数字化大潮的到来， 关系数据库(SQL) 又面临着新的机遇和挑战。对于 IT 行业的从业人员，了解关系数据库 和 SQL 新的发展，对于解决企业 IT 的核心问题十分必要。 SQL 的现在 ","date":"2018-08-07","objectID":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/:0:0","tags":["关系型数据库","NewSQL","NoSQL"],"title":"SQL：数据世界的通用语","uri":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/"},{"categories":["数据库"],"content":"Not Only SQL NoSQL 的兴起是对于传统的关系型数据库（SQL) 的最近的一次颠覆尝试。有几个原因导 致了 NoSQL 的兴起： 相对于传统的关系型数据库，NoSQL 更容易为企业提供更好数据库可扩展性，是的企 业能够应对日益增长的庞大的数据量。 相比于传统的关系型数据库，很多优秀的 NoSQL 以开源的形式存在。 很多操作在关系型数据库中没有支持，比如 JSON 数据格式全文搜索。 没有严格的 Schema 限制，因此在很多情况下比较灵活。 然而很快，NoSQL 便暴露除了很多不足： 没有标准的数据查询语言，不同的 NoSQL 提供了不同且不完备的 SQL 替代品；随着 应用程序的演进，应用程序所累积的数据会越来越多，数据之间的关系会变得越来越 复杂，在这种情况下由于 NoSQL 所提供的简单的数据查询语句不成熟且不完备，尤 其是考虑到 NoSQL 没有严格的 Schema 限制的情况下，导致大量的应用程序和数据 库之间的脆弱的胶水代码。 NoSQL 中很多数据处理和聚合实际上都是开发人员在应用程序中手写，相比于 SQL 广泛的标准适用性和成熟的优化方案，NoSQL 在处理数据之间的多对一和多对多关系 以及数据之间的关联时，性能差距非常明显。 人们很快发现，原来 NoSQL 的真正的意思是 Not Only SQL。 ","date":"2018-08-07","objectID":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/:1:0","tags":["关系型数据库","NewSQL","NoSQL"],"title":"SQL：数据世界的通用语","uri":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/"},{"categories":["数据库"],"content":"要水平扩展，也要 SQL 2017 年 Google 发布论文 Spanner:Becoming a SQL System1 在这篇论文里，有如下描 述： 尽管这些 NoSQL 系统提供了一些优势，但也确实了很多传统的关系型数据库所拥有的、 程序员所依赖的功能。其中最关键的是缺失了健壮的数据库查询语句，其后果是开发 人员需要在应用程序中手写复杂的数据处理和聚合的逻辑。因此，Google 决定将 Spanner 转变为提供全部 SQL 特性的系统。查询的执行跟 Spanner 的其他架构特性 紧密集成。 论文的后续部分还总结了 Spanner 从 NoSQL 到 SQL 的转变原因： 尽管 NoSQL 功能使得用户可以很简易的加载 Spanner，在一些简单的应用场景中也显 得十分有用； 但 SQL 在复杂数据读取和数据运算方面提供了显著的价值。 无独有偶，2017年8月，Kafka 发布了流式 SQL 引擎 KSQL ，为 Kafka 在处理数据时， 提供完整的 SQL 支持。 不仅仅 Kafka，RabbitMQ、Spark、Flink 等纷纷开始支持 SQL。 这种趋势正是目前正在进行当中的 NewSQL2 大潮。其目标是提供 NoSQL 一样的水 平扩展能力的和同等读写性能的情况下，支持保证原子性、一致性、隔离性和持久性 (ACID) 的事务。也就是说在可扩展性方面匹敌 NoSQL，但同时保留关系型数据库模型。 就目前来看 NewSQL 大体上可以分为三类： 全新的设计的 NewSQL 系统，包括 Google Spanner、CockroachDB 和 ClustrixDB 等。 基于分片中间件的传统数据库集群，比如 Oracle 就提供了 MySQL 的 proxy。 云化的数据库服务 (DBaaS)，其中最成功的莫过于 AWS Aurora 尽管新的技术不断涌现，但 SQL 这一古老的技术示出 强大的生命力 ；作为一个广泛 使用的标准技术，在大数据随处可见的今天， 宛然成为数据世界的通用语 。这背后 的原因是什么呢？ 首先 SQL 一个成熟的标准。SQL 诞生于1974年，并在1986年正式成为国际标准。随 后尽管数据库系统如过江之鲫，但大体上这些数据库还是会遵守这个标准。 SQL 是一个非常优秀的抽象模型；对于使用者来讲，SQL 简单易用，不用关心 SQL 背后的诸如存储、同步及先写日志等细节；对于数据库的实现着来讲，SQL 对于如何 实现查询完全没有约束，使得查询优化成为可能，且查询优化比绝大多数普通程序员 基于 C 和 C++ 手写的形同逻辑的实现性能更胜一筹。 基于 SQL 的极致性能优化。基于生产力的考量，现代的开发大多基于高阶语言，这 些高阶语言大多基于通用的抽象模型，比如 SQL 基于关系型代数3 ，然而站在 CPU 执行的角度来看，所有的这些通用抽象模型无一例外都是以增加额外的开销，也 就是牺牲性能为代价；但最近运行时 SQL 编译技术的兴起使得牺牲性能最小化，开 发人员基于 SQL 快速开发业务，SQL 在运行时由 LLVM 编译成机器码4 已获得 最佳的性能。也就是说使用 SQL 兼顾了生产力和性能。 总结 SQL 这一古老的技术，实际上是一个非常优秀的抽象模型，对使用者来讲简单易用；对数 据库开发者来讲可以灵活的优化；因此展现出十分强大的生命力，随着 NewSQL 的兴起， 在数据日益重要的今天，逐渐成为数据世界的通用语。 引用 1 https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46103.pdf 2 https://15721.courses.cs.cmu.edu/spring2018/papers/01-intro/pavlo-newsql-sigmodrec2016.pd://15721.courses.cs.cmu.edu/spring2018/papers/01-intro/pavlo-newsql-sigmodrec2016.pdf 3 https://en.wikipedia.org/wiki/Relational_algebra 4 https://15721.courses.cs.cmu.edu/spring2018/papers/03-compilation/p539-neumann.pdf ","date":"2018-08-07","objectID":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/:2:0","tags":["关系型数据库","NewSQL","NoSQL"],"title":"SQL：数据世界的通用语","uri":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/"},{"categories":["数据库"],"content":"作者的其他数据库文章链接 SQL：数据世界的通用语 数据库性能之翼：SQL 语句运行时编译 每周一论文：A Survey of B-Tree Locking Techniques 每周一论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control 数据库索引数据结构总结 ","date":"2018-08-07","objectID":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/:3:0","tags":["关系型数据库","NewSQL","NoSQL"],"title":"SQL：数据世界的通用语","uri":"https://zhewuzhou.github.io/posts/sql_as_universe_language_in_data_world/"},{"categories":["区块链"],"content":"目录 目录 摘要 问题由来 顺序 区块链是分布式系统 工作量证明即分布式时钟，时钟的基本单位十分钟 每个矿工都是时间的创造者 统一的时钟和顺序 工作量证明即时钟 摘要 本文试图从分布式系统（分布式时钟）的角度理解区块链（比特币，下同）的一致性；实 际上区块链之所以安全可信，工作量证明是主要原因，数字签名和哈希校验是辅助性因素。 比特币系统的交易并非立即可信，通常支付发起后需要等一个小时交易才算正式生效，大 宗交易甚至要等 二十四个小时；等待时间的背后，正是比特币基于工作量证明的 渐进 式 信任机制。 比特币系统是一个去中心化的分布式系统，其网路内所有的节点身份均等；因此渐进式的 信任机制的本质是 工作量证明所构建分布式时钟。 本文从“双花”问题展开，通过不断提问的方式逐步接近本文的主题。 问题由来 “双花”问题是区块链系统上的主要安全问题之一；在去中心化的 P2P 网络上，由于数据 的可复制性，使得系统可能存在同一笔数字资产因不当操作被重复使用的情况。现实世界 中纸币天然的屏蔽了这个问题，即便是网上交易，在大银行主导的中心化的支付网络上， 个人用户复制数据进行“双花”基本上不可能，因此也鲜有“双花”的问题。 一个典型的区块链上双花问题场景如下： Bob 拥有一幅价值 $250000 的名家画作，她希望通过 Bitcoin 系统卖出这幅画作。 Alice 对这幅画作很感兴趣，Alice 通过区块链系统，向 Bob 支付了价值 $250000 的比 特币。 Bob 等了一段时间，看到区块链上已经有若干个确认（即当前交易所在区块之后新增了 区块）后，将画作发送给 Bob 假设 Alice 拥有整个区块链网络中 51% 的算力，Alice 可以重新挖矿，对这笔交易和这笔 交易所在的块进行共识攻击；由于 Alice 拥有 51% 的算力，因此很快共识攻击所在的区 块链分叉上的区块数很快就超过正常交易的分叉 最终 Alice 在没有想 Bob 支付任何比特币的情况下，得到价值高昂的画作。 关于“双花”问题，有非常多的解释，然而几乎所有的解释都是基于区块链分叉进行的， 那么问什么双花就一定会引起取款连分叉呢？或者说共识攻击几乎都要通过区块链分叉 进行呢？ 顺序 在区块链系统中所有的交易都需要提供输入交易，也就是发生在当前交易之前的比特币来 源交易，如果只有一条链路，那么当矿工验证交易合理性的时候就能很容易的发现双花的 问题；因此真正有威胁的双花问题都是利用了分布式网络中暂时存在的不一致性，如下图 所示： 假设在比特币网络中，一个矿工看到的是上面的分支，另一矿工看到的是下面的分支，由 于比特币的来源交易是合法的，那么这两个矿工看到的交易都是合法的，假设这两个矿工 分别找到了答案，获得将这两笔交易写入区块链的权利，那么在写入的时候实际上形成了 区块链分支，区块链的其他参与者在收到广播的时候无从判断到底那一笔是双花，只有等 待一段时间后，选择相信更长的分支。 因为有潜在“双花”问题的风险，因此交易双方需要等待确认，通常等一个小时，当前交易 区块后面有六个区块后，双方才会认为交易可信，选择一个小时并不意味着绝对可信，而 是在攻击难度和交易效率之间的折中。双花问题之所以很有威胁，就在于两笔交易的顺序 不定，同一个比特币来源交易之后到底支撑哪一笔后续交易，存在变数；不同的区块链节 点对短时间内无法达到共识。 实际上，在比特币系统中，交易的顺序确定是共识的核心。人们无法花费尚未产生的比特 币，输入验证就是要保证比特币的产生先于比特币的花费；而当有了分歧（分支）之后选 择相信更长的分支，实际上确定一笔合法的比特币来源交易和消费交易顺序的过程。一旦 确定了交易的顺序，比特币系统中的所有的交易就形成了一个线性的链条，所有交易之前 的顺序确定且不可修改。 现实生活中，人类用时间来确定事物发生的顺序，这个时间通常通过原子钟之类的工具测 定出来，形成大家所熟知的年月日，但年月日本身并不重要，重要的是我们可以通过年月 日所构成的时间戳来确定事件的顺序。那么在比特币系统中， 交易顺序是如果确定的呢？ 区块链是分布式系统 区块链是一个去中心化的分布式系统，交易产生于不同的节点，并没有可信的第三方能够 保证交易的顺序；也许有人会说在节点生成交易的时候附带着时间戳，这样交易就会有序； 然而一个显而易见的问题是这个时间戳可信么？ 实际上分布式系统中没有绝对的全局时钟，各个物理设备上的本地时钟也不是准确的，因 此单纯的时间戳不可能使得区块链上的交易有序。这个问题的详细描述来自于 Lamport 的论文 Time, Clocks, and the Ordering of Events in a Distributed System。 时间是人类的“概念”，其具体形式可以是诸如原子钟之类，本质上它们都属于可信的第三 方，比如北京时间。人们使用时间，相信时间，并非对年月日等数字有有兴趣，而是用来 确定日常生活这种事务的顺序。 基于上面的论述，Bitcoin 系统中没有可信的第三方，没法使用基于可信第三方的时间戳， 既然时间戳不可信，那么区块链系统就必须要通过别的方式解决这个问题。理解了区块链 如何通过非时间戳的方式确定顺序，就理解了区块链的核心概念。 工作量证明即分布式时钟，时钟的基本单位十分钟 区块链确定链上交易顺序的秘密，就隐藏在工作量证明的机制中。工作量证明的说到底就 暴力猜测给定哈希值的输入，具体细节，可以参考这篇文章。工作量证明的重要 重要属 性如下： 无记忆性 - 人类是一种善于学习的动物，当人类面对复杂问题的时候，最自然的做法 就是通过不断地增加尝试次数渐进式学习，第二次比第一次好，第三次比第二次有改 进；然而无记忆性强调的是每次尝试都是独立的，相互之间没有因果关系。一个简单 的例子是即便前十次抛硬币的结果都是背面，也不能让人完全确信下一次一定是背面。 工作量证明也是一样的，不论之前做了多久的哈希猜测，下一次发现答案的概率是一 样的。 无记忆性 是 无进展性 的基础，在计算哈希值得过程中，每一次尝试都是独立的， 多尝试一次并没有让矿工更加接近答案，换言之多多猜测一次并没有让找到答案的过 程更进一步。 找到答案取决于且仅取决于矿工猜测哈希的速率。 由于找到答案取决于且取决于矿工的猜测速率也就是运算能力，因此随着矿工运算能力的 增加，比特币系统每个一段时间就会调整猜测的难度，保证猜出下一个答案基本上在十分 钟左右。 比特币系统中，区块链上的区块每十分钟增加一个；通过相信更长的分支，所有交易之间 的顺序被唯一确定； 从确定事物发生的顺序这个角度上讲 ， 工作量证明就是比特 币系统中的分布式时钟，按照现实世界时间每隔十分钟拨动一次。在两次拨动之间什么 都不会发生，换言之区块链上基本时间单位相当于现实中的十分钟。 每个矿工都是时间的创造者 在区块链上，矿工们各自计算答案，并没有一个中心化的机构批准谁有资格进行计算；矿 工们在各自计算的时候并不互相交流，仅需要在找到答案后公布出来。尽管下一个区块所 需要矿工们提供的答案可以有很多个，但大家最终认同的答案是惟一的，因此可以认为矿 工们工作在同一个问题上，尽管没有沟通。 因此每一个矿工都是区块链上时钟的创造者；由于工作量证明的无进展性，因此可以认为 每一次哈希值猜测都是为时钟的创造做贡献，即使立即离开。 在区块链上每一个矿工的每一次哈希猜测都在为区块链上的时钟创造做贡献，随着矿工的 不断地加入和离开，区块链上的时钟不断地向前拨动； 大家共同创造分布式时钟 ， 大家也共同信任基于此分布式时钟确定的交易顺序 。 统一的时钟和顺序 本质上，哈希值的猜测是无进展性，并且哈希函数可以接受任意字符串；因此工作量证明 即便是不以区块的哈希头作为输入一样能够工作。 然而如果输入不是区块的头，尽管我们可以通过工作量证明得到一个分布式时钟，但是我 们没有办法将这个时钟和区块链上的顺序结合在一起，尽管时钟在拨动，但交易的顺序并 没有在时钟拨动的过程中得到确认。而通过将区块的头作为输入值，分布式时钟拨动就意 味着交易顺序被确定，且顺序确定除了分布式时钟的拨动没有其他的方式。 也就是说 工作量证明不仅仅意味着分布式时钟的拨动，也意味着着基于时钟拨动的交易顺序被物 理的确定下来。 在分布式时钟拨动的过程中，工作量证明的积累越来越多，形成基于哈希指针的链条，也 即区块链：工作量证明即时钟 本文从双花问题出发，引出区块链上顺序的问题；而顺序的核心是分布式时钟，在比特币 系统中工作量证明即创造了分布式时钟，且通过巧妙的将区块哈希头作为工作量证明的输 入，比特币系统将分布式时钟和链上交易顺序的确定统一。 ","date":"2018-07-04","objectID":"https://zhewuzhou.github.io/posts/pow_as_distributed_clock/:0:0","tags":["分布式","共识","双花"],"title":"工作量证明即分布式时钟","uri":"https://zhewuzhou.github.io/posts/pow_as_distributed_clock/"}]